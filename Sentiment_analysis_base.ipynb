{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение тональности текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используется выборка с отзывами на фильмы [sentence polarity dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz)\n",
    "В ней содержатся предложения с отрицательными и положительными отзывами (по 5331)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import collections, itertools, functools\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "POLARITY_DATA_DIR = os.path.join('polarityData', 'rt-polaritydata')\n",
    "RT_POLARITY_POS_FILE = os.path.join(POLARITY_DATA_DIR, 'rt-polarity-pos.txt')\n",
    "RT_POLARITY_NEG_FILE = os.path.join(POLARITY_DATA_DIR, 'rt-polarity-neg.txt')\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальная модель: наивный Байес. Каждому предложению сопоставляется бинарный bag-of-words вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def use_all(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "def getWords(file_path, type_of_feature=None, feature_select=None, apply_features=True):\n",
    "    features = []\n",
    "    with open(file_path, 'r') as sentences:\n",
    "        for sentence in sentences:\n",
    "            words = re.findall(r\"[\\w']+|[.,!?;]\", sentence.rstrip())\n",
    "            if apply_features:\n",
    "                words = [feature_select(words), type_of_feature]\n",
    "            features.append(words)\n",
    "    return features\n",
    "\n",
    "def evaluate(feature_selector, show_features=False):\n",
    "    pos_features = getWords(RT_POLARITY_POS_FILE, 'pos', feature_select=feature_selector)\n",
    "    neg_features = getWords(RT_POLARITY_NEG_FILE, 'neg', feature_select=feature_selector)\n",
    " \n",
    "    train_fraction = int(len(pos_features)*3/4)\n",
    "    \n",
    "    train_features = neg_features[:train_fraction] + pos_features[:train_fraction]\n",
    "    test_features = neg_features[train_fraction:] + pos_features[train_fraction:]\n",
    "    clf = NaiveBayesClassifier.train(train_features)\n",
    "    actual_labels = collections.defaultdict(set)\n",
    "    pred_lables = collections.defaultdict(set)\n",
    "    for num, (features, label) in enumerate(test_features):\n",
    "            actual_labels[label].add(num)\n",
    "            observed = clf.classify(features)\n",
    "            pred_lables[observed].add(num)\n",
    " \n",
    "    print 'accuracy:', nltk.classify.util.accuracy(clf, test_features)\n",
    "    print 'precision:', nltk.metrics.precision(actual_labels['pos'], pred_lables['pos'])\n",
    "    print 'recall:', nltk.metrics.recall(actual_labels['pos'], pred_lables['pos'])\n",
    "    if show_features:\n",
    "        clf.show_most_informative_features()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.773068267067\n",
      "precision: 0.787066246057\n",
      "recall: 0.748687171793\n"
     ]
    }
   ],
   "source": [
    "evaluate(use_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем повысить качество модели. Вначале уберем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.764066016504\n",
      "precision: 0.765060240964\n",
      "recall: 0.762190547637\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopset = set(stopwords.words('english'))\n",
    " \n",
    "def stopword_filtered_word_feats(words):\n",
    "    return dict([(word, True) for word in words if word not in stopset])\n",
    " \n",
    "evaluate(stopword_filtered_word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество только ухудшилось, следовательно стоп-слова помогают в определении тональности. Попробуем добавить в признаки самые значимые биграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.781695423856\n",
      "precision: 0.791311093871\n",
      "recall: 0.765191297824\n"
     ]
    }
   ],
   "source": [
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=50):\n",
    "    all_bigrams = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = all_bigrams.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\n",
    "\n",
    "evaluate(bigram_word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество немного выросло, теперь попробуем понизить размерность выборки, используя хи-квадрат метрику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.846586646662\n",
      "precision: 0.867834394904\n",
      "recall: 0.817704426107\n"
     ]
    }
   ],
   "source": [
    "def get_best_words(num=10000):\n",
    "    word_freq = FreqDist()\n",
    "    label_freq = ConditionalFreqDist()\n",
    "\n",
    "    for word in itertools.chain(*getWords(RT_POLARITY_POS_FILE, 'pos', apply_features=False)):\n",
    "        word_freq[word.lower()] += 1\n",
    "        label_freq['pos'][word.lower()] += 1\n",
    "\n",
    "    for word in  itertools.chain(*getWords(RT_POLARITY_NEG_FILE, 'neg', apply_features=False)):\n",
    "        word_freq[word.lower()] += 1\n",
    "        label_freq['neg'][word.lower()] += 1\n",
    "\n",
    "    pos_word_count = label_freq['pos'].N()\n",
    "    neg_word_count = label_freq['neg'].N()\n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "\n",
    "    word_scores = {}\n",
    "\n",
    "    for word, freq in word_freq.iteritems():\n",
    "        pos_score = BigramAssocMeasures.chi_sq(label_freq['pos'][word],\n",
    "            (freq, pos_word_count), total_word_count)\n",
    "        neg_score = BigramAssocMeasures.chi_sq(label_freq['neg'][word],\n",
    "            (freq, neg_word_count), total_word_count)\n",
    "        word_scores[word] = pos_score + neg_score\n",
    "\n",
    "    best = sorted(word_scores.iteritems(), key=lambda (w,s): s, reverse=True)[:num]\n",
    "    bestwords = set([w for w, s in best])\n",
    "    return bestwords\n",
    " \n",
    "def best_word_feats(words, bestwords):\n",
    "    return dict([(word, True) for word in words if word in bestwords])\n",
    " \n",
    "evaluate(functools.partial(best_word_feats, bestwords=get_best_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь качество улучшилось более значительно, посмотрим на ключевые слова, позволяющие определить тональность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.846586646662\n",
      "precision: 0.867834394904\n",
      "recall: 0.817704426107\n",
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     17.0 : 1.0\n",
      "                   quiet = True              pos : neg    =     15.7 : 1.0\n",
      "                mediocre = True              neg : pos    =     13.7 : 1.0\n",
      "               absorbing = True              pos : neg    =     13.0 : 1.0\n",
      "                portrait = True              pos : neg    =     12.4 : 1.0\n",
      "                   flaws = True              pos : neg    =     12.3 : 1.0\n",
      "              refreshing = True              pos : neg    =     12.3 : 1.0\n",
      "               inventive = True              pos : neg    =     12.3 : 1.0\n",
      "                 triumph = True              pos : neg    =     11.7 : 1.0\n",
      "            refreshingly = True              pos : neg    =     11.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(functools.partial(best_word_feats, bestwords=get_best_words()), show_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
